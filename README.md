# 프로세스와 스레드

### 프로세스란
- 프로세스는 실행 중인 프로그램으로 디스크로부터 메모리에 적재되어 CPU의 할당을 받을 수 있는 상태
- 운영체제로부터 
    - 함수의 매개변수, 복귀주소와 로컬 변수와 같은 임시적인 자료를 가지는 프로세스 스택
    - 전역 변수들을 수록하는 데이터 섹션
    - 프로세스 실행 중 동적으로 할당되는 힙
- 실행 파일이 메모리에 적재될 때 프로세스가 됨

### 프로세스 제어 블록 (PCB, Process Control Block)
- 각 프로세스는 프로세스 제어 블록에 의해 표현된다
- PCB는 특정 프로세스에 대한 중요한 정보를 나타내는 운영체제의 자료구조
- 단순하게, 프로세스마다 달라지는 모든 정보 저장하며 프로세스의 생성과 동시에 고유한 PCB가 생성됨.
- 프로세스는 CPU를 할당받아 작업을 처리하다가도 프로세스 전환이 발생하면 진행하던 작업을 저장하고, CPU를 반환하는데 이 때 작업의 진행 상황을 모두 PCB에 저장

- PCB에 저장되는 정보
    - 프로세스 식별번호(PID, Process ID)
    - 프로세스 상태 : new, ready, running, waiting, halted 상태 등..
    - 프로그램 카운터 : 해당 프로세스 다음에 실행할 명령어의 주소
    - CPU 레지스터들 : 컴퓨터의 구조에 따라 다양한 수와 타입을 가짐
    - CPU 스케쥴링 정보 : 프로세스의 우선순위, 스케줄 큐에 대한 포인터
    - 메모리 관리 정보 : 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보 포함
    - 입출력 상태 정보 : 프로세스에 할당된 입출력 장치들과 열린 파일 목록
    - 어카운팅 정보 : 사용된 PCU시간, 경과된 시간 등..
    
### 스레드란 (Thread)
- 한 프로세스 내에서 동작되는 여러 실행 흐름
- 프로세스 내의 주소 공간이나 자원 공유 가능
- 스레드 구성
    - 스레드 ID, 프로그램 카운터, 레지스터 집합, 스택

- **스택을 스레드마다 독립적으로 할당하는 이유**
    - 스택은 함수 호출 시 전달되는 인자, 되돌아갈 주소 값 및 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간으로 스택 메모리 공간이 독립적이여야 독립적인 함수 호출이 가능

- **PC Register를 스레드마다 독립적으로 할당하는 이유**
    - PC값은 스레드가 명령어의 어디까지 수행하였는지를 나타냄
    - 스레드는 CPU를 할당 받았다가 스케쥴러에 의해 잠시 뻇긴다. 
    - 추후에 어느 부분부터 수행해야 하는지 기억을 위해 독립적으로 할당

### 멀티스레드 vs 멀티 프로세스
- 멀티 프로세스는 프로세스간 공유하는 자원이 없기에 동일한 자원에 동시에 접근하는 일이 없음
- 멀티 스레드로 작업시에는 서로 다른 스레드가 데이터와 힙 영역을 공유하기 때문에 동기화 작업 필요

- 멀티스레드의 장점
    - 멀티 스레드는 멀티 프로세스보다 문맥 전환(context switch)이 빠르다
        - 스레드의 Context switch는 프로세스 Context switch와는 달리 캐시 메모리를 비울 필요가 없기 때문에 더 빠르다
    - 멀티 프로세스보다 많은 메모리 공간과 CPU시간 차지한다
    - 스레드 간의 통신시 별도의 자원을 이용하는 것이 아닌 전역 변수의 공간 또는 동적으로 할당된 공간인 Heap영역을 이용하여 데이터를 주고받는다.
- 멀티스레드의 단점
    - 오류로 인해 스레드 하나가 종료시 전체 스레드가 종료될 수 있다
    - 동기화를 통한 작업 처리 순서 컨트롤 및 공유 자원에 대한 접근 컨트롤 (병목현상 발생으로 인한 성능저하)
    
    
## 문맥교환(Context Switch)
- 인터럽트 발생시 운영체제가 CPU를 현재 작업에서 빼앗아 커널 루틴에서 실행할 수 있게 함
- 인터럽트 종료 후 과거 처리하던 문맥을 복구할 수 있도록 이전의 프로세스의 상태를 보관하고 새로운 프로세스의 보관된 상태를 복구하는 작업이 필요
- 커널은 과거 프로세스의 문맥을 PCB에 저장하고, 실행이 스케줄된 새로운 프로세스의 저장된 문맥을 복구함

--- 

## CPU 스케줄러

### FCFS(First Come First Served)
- 즉 먼저 온 순서대로 처리 / 비선점형(Non-Preemptive) 스케줄링
- 일단 CPU 를 잡으면 CPU burst 가 완료될 때까지 CPU 를 반환하지 않는다. 할당되었던 CPU 가 반환될 때만 스케줄링이 이루어진다.
- 문제점
    - convoy effect / 소요시간이 긴 프로세스가 먼저 도달하여 효율성을 낮추는 현상이 발생한다.

### SJF(Shortest - Job - First)
- 다른 프로세스가 먼저 도착했어도 CPU burst time 이 짧은 프로세스에게 선 할당
- 비선점형(Non-Preemptive) 스케줄링
- 문제점
    - starvation / 이 스케줄링은 극단적으로 CPU 사용이 짧은 job 을 선호 / 사용 시간이 긴 프로세스는 거의 영원히 CPU 를 할당받을 수 없음

### SRT(Shortest Remaining time First)
- 새로운 프로세스가 도착할 때마다 새로운 스케줄링이 이루어진다. / 선점형 (Preemptive) 스케줄링
- 현재 수행중인 프로세스의 남은 burst time 보다 더 짧은 CPU burst time 을 가진 새로운 프로세스가 도착하면 CPU 를 뺏김
- 문제점
    - starvation / 새로운 프로세스가 도달할 때마다 스케줄링을 다시하기 때문에 CPU burst time(CPU 사용시간)을 측정할 수가 없다.

### Priority Scheduling
- 우선순위가 가장 높은 프로세스에게 CPU 를 할당하는 스케줄링 
- 선점형 스케줄링(Preemptive) 방식
    - 더 높은 우선순위의 프로세스가 도착하면 실행중인 프로세스를 멈추고 CPU 를 선점한다.
- 비선점형 스케줄링(Non-Preemptive) 방식
    - 더 높은 우선순위의 프로세스가 도착하면 Ready Queue 의 Head 에 넣는다.
- 문제점
    - starvation / 무기한 봉쇄(Indefinite blocking) / 실행 준비는 되어있으나 CPU 를 사용못하는 프로세스를 CPU 가 무기한 대기하는 상태

### Round Robin
- **현대적인 CPU 스케줄링** / 각 프로세스는 동일한 크기의 할당 시간(time quantum)을 갖게 된다.
- 할당 시간이 지나면 프로세스는 선점당하고(뻇기고) ready queue 의 제일 뒤에 가서 다시 줄을 선다.
- RR은 CPU 사용시간이 랜덤한 프로세스들이 섞여있을 경우에 효율적
- RR이 가능한 이유는 프로세스의 context 를 save 할 수 있기 때문이다.
- 장점
    - Response time이 빨라진다.
    - n 개의 프로세스가 ready queue 에 있고 할당시간이 **CPU 전체 시간의 1/n** 을 얻는다. 즉, 어떤 프로세스도 (n-1)q time unit 이상 기다리지 않는다.
    - 프로세스가 기다리는 시간이 CPU 를 사용할 만큼 증가한다.
    - 공정한 스케줄링이라고 할 수 있다.

--- 

## 동기(Sync)와 비동기(ASync)의 차이
- 해야할 일(task)가 빨래, 설거지, 청소 세 가지
    - 동기적으로 처리한다면 빨래를 하고 설거지를 하고 청소를 한다.
    - 비동기적으로 일을 처리한다면 빨래하는 업체에게 빨래를 / 설거지 대행 업체에 설거지를 / 청소 대행 업체에 청소를 시킨다.
    - 셋 중 어떤 것이 먼저 완료될지는 알 수 없으며, 이 때는 백그라운드 스레드에서 해당 작업을 처리하는 경우의 비동기를 의미한다.

- 동기 (Sync)
    - 일반적으로 동기와 비동기의 차이는 메소드를 실행시킴과 동시에 반환 값이 기대되는 경우
    - 동시에라는 말은 실행되었을 때 값이 반환되기 전까지는 blocking되어 있다는 것을 의미
- 비동기 (Async)
    - 비동기의 경우, blocking되지 않고 이벤트 큐에 넣거나 백그라운드 스레드에게 해당 task 를 위임하고 바로 다음 코드를 실행하기 때문에 기대되는 값이 바로 반환되지 않음
    
## 프로세스 동기화
### Critical Section(임계영역)
- 멀티 스레딩시 동일한 자원을 동시에 접근하는 경우(e.g. 공유하는 변수 사용, 동일 파일을 사용 등)을 실행하는 코드 영역
- 각 프로세스에서 공유 데이타를 액세스하는 프로그램 코드 부분

### Critical Section Solution (임계영역 사용)
- Lock : 하드웨어 기반 해결책으로써, 동시에 공유 자원에 접근하는 것을 막기 위해 Critical Section 에 진입하는 프로세스는 Lock 을 획득하고 Critical Section 을 빠져나올 때, Lock 을 방출 / 한계 : 다중처리기 환경에서는 시간적인 효율성 측면에서 적용할 수 없음

---

## Semaphores(세마포어)와 Mutex(뮤텍스)
- 소프트웨어상의 임계구역 문제 해결책
- 하드웨어상으로는 복잡하고 응용 프로그래머들이 사용하기 힘들어 고안

### Mutex Exclusion (상호 배제)
- 공유된 자원의 데이터를 여러 쓰레드가 접근하는 것을 막음 (locking과 unlocking을 사용)
- Critical Section을 가진 스레드들의 Running time이 서로 겹치지 않게 각각 단독으로 실행되게 하는 기술
- 한 스레드가 임계구역을 실행하는 동안, 다중 스레드는 다른 처리기에서 회전을 수행

### Semaphores(세마포어)
- 공유된 자원의 데이터를 여러 프로세스가 접근하는 것을 막음
- 세마포어는 운영체제 또는 커널의 지정된 저장장치 내 값으로서, 각 프로세스는 이를 확인하고 변경 가능
- 가용한 개수를 가진 자원에 대한 접근 제어용으로 사용, 세마포는 그 가용한 자원의 개수 로 초기화, 자원을 사용하면 세마포가 감소, 방출하면 세마포가 증가
- 즉 세마포 카운트오 더블어 Flag 느낌의 제어

### 뮤텍스 vs 세마포어 차이점
- Semaphores는 Mutex가 될 수 있지만 Mutex는 Semaphores가 될 수 없음 (Mutex는 상태가 0,1), Semaphores는 (0, 1, 카운트값)
- Semaphores는 시스템 범위에 걸쳐있고 파일시스템상의 파일 형태로 존재 , Mutex는 프로세스범위를 가지며 프로세스가 종료될때 자동으로 clean up
- **(가장큰차이점)** 뮤텍스는 동기화 대상이 오직 하나뿐일때, 세마포어는 동기화 대상이 하나 이상일 때 사용

### Deadlock(교착상태)
- 둘 이상의 프로세스가 Critical Section 진입을 무한정 기다리고 있고, Critical Section 에서 실행되는 프로세스는 진입 대기 중인 프로세스가 실행되야만 빠져나올 수 있는 상황을 지칭 (서로 엉킨느낌)
- 서로 원하는 리소스가 상대방에게 할당되어 있어 무한정 기다리게 되는 상황

### 교착상태 예방법
- 상호 배제 부정 : 여러 개의 프로세스가 공유 자원 사용할 수 있게
- 점유 대기 부정 : 프로세스가 실행되기 전 필요한 모든 자원 할당
- 비선점 부정 : 자원을 점유하고 있는 프로세스가 다른 자원을 요구할 때 점유하고 있는 자원을 반납 가능하게

--- 

## 메모리 관리 전략
- 각각의 **프로세스** 는 독립된 메모리 공간을 갖고, 운영체제 혹은 다른 프로세스의 메모리 공간에 접근할 수 없는 제한이 걸려있다. 단지, **운영체제** 만이 운영체제 메모리 영역과 사용자 메모리 영역의 접근에 제약을 받지 않음

### Swapping
- 표준 Swapping 방식으로 round-robin 스케줄링의 다중 프로그래밍 환경에서 CPU 할당 시간이 끝난 프로세스의 메모리를 보조 기억장치(하드디스크)로 내보내고 다른 프로세스의 메모리를 불러 들임
- 이 과정을 swap이라하고, 주 기억장치(RAM)로 불러오는 과정을 **swap-in** / 보조 기억장치로 내보내는 과정을 **swap-out** 이라 함
- swap 에는 큰 디스크 전송시간이 필요하기 때문에 현재에는 메모리 공간이 부족할때 Swapping 이 시작됨

### **단편화** (**Fragmentation**)
- 프로세스들이 메모리에 적재되고 제거되는 일이 반복되다보면, 프로세스들이 차지하는 메모리 틈 사이에 사용 하지 못할 만큼의 작은 자유공간들이 늘어남 
- 외부 단편화
    - 메모리 공간 중 사용하지 못하게 되는 일부분
    - 물리 메모리(RAM)에서 사이사이 남는 공간들을 모두 합치면 충분한 공간이 되는 부분들 -> 압축기법가능하지만 작업효율 낮음
    - ex) **메모리 공간 10 Process A가 2, (자유공간0.3) Process B가 4, (자유공간0.7) Process C가 3 일 때 Process사이의 자유공간을 외부단편화라 함
    
- 내부 단편화
    - 프로세스가 사용하는 메모리 공간 에 포함된 남는 부분.
    - ex) **메모리 공간이 10이 있고 Process A 가 9.8 사용시 0.2라는 내부단편화 발생*


### Paging(페이징)
- 하나의 프로세스가 사용하는 메모리 공간이 연속적이어야 한다는 제약을 없앤 메모리 관리 방법
- 장점
    - 페이징 기법을 사용함으로써 **논리 메모리는 물리 메모리에 저장될 때, 연속되어 저장될 필요가 없고**
    - **물리 메모리의 남는 프레임에 적절히 배치됨으로 외부 단편화를 해결할 수 있는 큰 장점이 있음**
    - 하나의 프로세스가 사용하는 공간은 여러개의 페이지로 나뉘어서 관리, 개별 페이지는 **순서에 상관없이** 물리 메모리에 있는 프레임에 mapping 되어 저장

- 단점
    - 내부 단편화 문제의 비중이 늘어나게 됨
    - ex) **페이지 크기가 10 짜리가 3개, 프로세스 A가 21 의 메모리를 요구한다면 3개의 페이지 프레임과 9B가 남아 내부단편화발생**

### Segmentation(세그멘테이션)
- 페이징에서처럼 논리 메모리와 물리 메모리를 같은 크기의 블록이 아닌, 서로 다른 크기의 논리적 단위인 세그먼트(Segment)로 분할
- 사용자가 두 개의 주소로 지정(세그먼트 번호 + 변위)
- 세그먼트 테이블에는 각 세그먼트의 기준(세그먼트의 시작 물리 주소)과 한계(세그먼트의 길이)를 저장

- 단점
    - 서로 다른 크기의 세그먼트들이 메모리에 적재되고 제거되는 일이 반복되면, 많은 수의 작은 조각들로 나누어져 못 쓰게 될 수 있음(외부 단편화)

---

## 캐시의 지역성
### 캐시의 지역성 원리
- 캐시 메모리는 속도가 빠른 장치와 느린 장치간의 속도차에 따른 병목 현상을 줄이기 위한 범용 메모리
- CPU 가 어떤 데이터를 원할 것인가를 어느 정도 예측할 수 있어야 함
- 이 때 적중율(Hit rate)을 극대화 시키기 위해 데이터 지역성(Locality)의 원리를 사용

### 지역성 (Locality)
- Locality란 기억 장치 내의 정보를 균일하게 Access 하는 것이 아닌 어느 한 순간에 특정 부분을 집중적으로 참조하는 특성
- 이 데이터 지역성은 대표적으로 시간 지역성과 공간 지역성으로 나뉜다.
- 시간 지역성(Temporal Locality) : 최근에 참조된 주소의 내용은 곧 다음에 다시 참조되는 특성.
- 공간 지역성(Spatial Locality) : 대부분의 실제 프로그램이 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성

### 캐싱라인(Caching line) 
- 캐시에 데이터를 저장할 때 특정 자료구조를 사용하여 묶음으로 저장하는 방식
- 캐시(cache)는 프로세서 가까이에 위치하면서 빈번하게 사용되는 데이터를 놔두는 장소
- 캐시가 아무리 가까이 있더라도 찾고자 하는 데이터가 어느 곳에 저장되어 있는지 몰라 결국 모든 데이터를 순회해야 한다면 시간이 오래 걸리게 됨
- 캐싱라인에는 데이터의 메모리 주소 등을 기록해 둔 태그들의 묶음이 저장되며 Full Associative / Set Associative / Direct Map 등이 있음

---

## 가상 메모리
- 다중 프로그래밍을 실현하기 위해서는 많은 프로세스들을 동시에 메모리에 올려두어야 함
- 가상메모리는 **프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법** 이며, 프로그램이 물리 메모리보다 커도 된다는 장점이 있음
- 가상 메모리는 실제의 물리 메모리 개념과 사용자의 논리 메모리 개념을 분리한 것

### 프로세스간의 페이지 공유
- 각 프로세스들은 `공유 라이브러리`를 자신의 가상 주소 공간에 두고 사용하는 것처럼 인식하지만, 라이브러리가 올라가있는 `물리 메모리 페이지`들은 모든 프로세스에 공유되고 있는 것.

### Demand Paging(요구 페이징)
- 프로그램 실행 시작 시에 프로그램 전체를 디스크에서 물리 메모리에 적재하는 대신, 초기에 필요한 것들만 적재하는 전략
- 가상 메모리는 대개 페이지로 관리되며, 요구 페이징을 사용하는 가상 메모리에서는 실행과정에서 필요해질 때 페이지들이 적재됨
- 원리는 **한 번도 접근되지 않은 페이지는 물리 메모리에 적재되지 않는다.**

### 페이지 교체
- `요구 페이징` 에서 언급된대로 프로그램 실행시에 모든 항목이 물리 메모리에 올라오지 않기 때문에, 프로세스의 동작에 필요한 페이지를 요청하는 과정에서 **`page fault(페이지 부재)`가 발생하게 되면, 원하는 페이지를 보조저장장치에서 가져오게 됨** 
- 하지만, **만약 물리 메모리가 모두 사용중인 상황이라면, 페이지 교체**가 발생
- 방법
    - (1) 디스크에서 필요한 페이지의 위치를 찾는다
    - (2) `페이지 교체 알고리즘`을 통해 희생될(victim) 페이지를 선택
    - (3) 희생될 페이지를 디스크에 기록하고, 관련 페이지 테이블을 수정
    - (4) 새롭게 비워진 페이지 테이블 내 프레임에 새 페이지를 읽어오고, 프레임 테이블을 수정
    - (5) 사용자 프로세스 재시작

### 페이지 교체 알고리즘
- FIFO 페이지 교체
    - FIFO(first-in first-out)의 흐름
    - 먼저 물리 메모리에 들어온 페이지 순서대로 페이지 교체 시점에 먼저 나가게 됨
    - 단점
        - 처음부터 활발하게 사용되는 페이지를 교체해서 페이지 부재율을 높이는 부작용을 초래가능
        - `Belady의 모순`: 페이지를 저장할 수 있는 페이지 프레임의 갯수를 늘려도 되려 페이지 부재가 더 많이 발생하는 모순이 존재
        
- 최적 페이지 교체(Optimal Page Replacement)
    - `앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체`하는 것
    - 주로 비교용으로 많이 사용 (실제 구현보다는)
    - 장점
        - 알고리즘 중 가장 낮은 페이지 부재율을 보장
    - 단점 
        - 모든 프로세스의 메모리 참조의 계획을 미리 파악할 방법이 없기 때문에 구현시 어려움

- LRU 페이지 교체(Least-Recently-Used)
    - 가장 오랫동안 사용되지 않은 페이지를 선택하여 교체한다.
    - 대체적으로 `FIFO 알고리즘`보다 우수하고, `OPT알고리즘`보다는 그렇지 못한 모습을 보임

- **LFU 페이지 교체(Least Frequently Used) 
    - 참조 횟수가 가장 적은 페이지를 교체(활발하게 사용되는 페이지는 참조 횟수가 많아질 거라는 가정)
    - 어떤 프로세스가 특정 페이지를 집중적으로 사용하다, 다른 기능을 사용하게되면 더 이상 사용하지 않아도 계속 메모리에 머물게 됨
    - 최적(OPT) 페이지 교체를 제대로 근사하지 못하기 때문에, 잘 쓰이지 않음
    
--- 
